{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuqixuan/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import h5py\n",
    "import torch as t\n",
    "import ipywidgets as widgets\n",
    "from warnings import warn\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.curdir))\n",
    "from network.rtpose_vgg import get_model\n",
    "from network.post import decode_pose\n",
    "from evaluate.coco_eval import get_multiplier, get_outputs, handle_paf_and_heat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramenters & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_EXT = ['.mp4', '.avi', '.mpg', '.mpeg', '.mov']\n",
    "IMAGE_EXT = ['.jpg', '.png', '.bmp', '.jpeg', '.jpe', '.tif', '.tiff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = r\"/home/liuqixuan/datasets/UCF-101/\"\n",
    "input_type = \"1to1\" # choose from [\"1to1\", \"nto1\"]\n",
    "output_dir = r\"/home/liuqixuan/datasets/UCF-101_processed\"\n",
    "weight_file = r'./network/weight/pose_model.pth'\n",
    "input_ext = \"video\" # either choose from [\"image\", \"video\"] or define selfish extension-names\n",
    "output_ext = \".mp4\"\n",
    "frame_rate_ratio = 1 # analyze every [n] frames\n",
    "process_speed = 2 # int, 1 (fastest, lowest quality) to 4 (slowest, highest quality)\n",
    "resize_fac = 1.0 # minification factor\n",
    "output_length = None # int, frame count for output, None for input length\n",
    "show_visualize_process = True # show canvas through matplotlib\n",
    "rebuild_exist_file = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select GPU Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Process Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(model, oriImg, process_speed):\n",
    "    # Get results of original image\n",
    "    multiplier = get_multiplier(oriImg, process_speed)\n",
    "    with t.no_grad():\n",
    "        orig_paf, orig_heat = get_outputs(multiplier, oriImg, model, 'rtpose')\n",
    "\n",
    "        # Get results of flipped image\n",
    "        swapped_img = oriImg[:, ::-1, :]\n",
    "        flipped_paf, flipped_heat = get_outputs(multiplier, swapped_img, model, 'rtpose')\n",
    "\n",
    "        # compute averaged heatmap and paf\n",
    "        paf, heatmap = handle_paf_and_heat(orig_heat, flipped_heat, orig_paf, flipped_paf)\n",
    "    param = {'thre1': 0.1, 'thre2': 0.05, 'thre3': 0.5}\n",
    "    to_plot, canvas, joint_list, person_to_joint_assoc = decode_pose(oriImg, param, heatmap, paf)\n",
    "    return to_plot, canvas, joint_list, person_to_joint_assoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize I/O Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_1to1_io_paths(input_data, input_ext, output_dir, output_ext):\n",
    "    if not os.path.exists(input_data):\n",
    "        raise FileNotFoundError(\"File not exist in {}\".format(input_data))\n",
    "    io_paths = {\"input\": [], \"output\": []}\n",
    "    if os.path.isdir(input_data):\n",
    "        for root, dirs, files in os.walk(input_data):\n",
    "            rel_path = os.path.relpath(root, input_data)\n",
    "            for file in files:\n",
    "                name, ext = os.path.splitext(file)\n",
    "                if ext.lower() in input_ext:\n",
    "                    input_path = os.path.join(root, file)\n",
    "                    output_path = os.path.join(output_dir, rel_path, name + output_ext)\n",
    "                    io_paths[\"input\"].append(input_path)\n",
    "                    io_paths[\"output\"].append(output_path)\n",
    "                else:\n",
    "                    warn(\"Unsupported format: %s\" % file)\n",
    "    else:\n",
    "        name, ext = os.path.splitext(input_data)\n",
    "        assert ext.lower() in input_ext, \"Unsupported format: %s\" % input_data\n",
    "        output_path = os.path.join(output_dir, os.path.basename(name) + output_ext)\n",
    "        io_paths[\"input\"].append(input_data)\n",
    "        io_paths[\"output\"].append(output_path)\n",
    "    return io_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_Nto1_io_paths(input_data, input_ext, output_dir, output_ext):\n",
    "    if not os.path.exists(input_data):\n",
    "        raise FileNotFoundError(\"File not exist in {}\".format(input_data))\n",
    "    io_paths = {\"input\": [], \"output\": []}\n",
    "    if os.path.isdir(input_data):\n",
    "        for root, dirs, files in os.walk(input_data):\n",
    "            rel_path = os.path.relpath(root, input_data)\n",
    "            image_list = []\n",
    "            for file in files:\n",
    "                name, ext = os.path.splitext(file)\n",
    "                if ext.lower() in input_ext:\n",
    "                    image_path = os.path.join(root, file)\n",
    "                    image_list.append(image_path)\n",
    "                else:\n",
    "                    warn(\"Unsupported format: %s\" % file)\n",
    "            if len(image_list) > 0:\n",
    "                output_path = os.path.join(output_dir, rel_path + output_ext)\n",
    "                image_list = sorted(image_list)\n",
    "                io_paths[\"input\"].append(image_list)\n",
    "                io_paths[\"output\"].append(output_path)\n",
    "    else:\n",
    "        name, ext = os.path.splitext(input_data)\n",
    "        assert ext.lower() in input_ext, \"Unsupported format: %s\" % input_data\n",
    "        output_path = os.path.join(output_dir, os.path.basename(name) + output_ext)\n",
    "        io_paths[\"input\"].append([input_data])\n",
    "        io_paths[\"output\"].append(output_path)\n",
    "    return io_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video_frames(video_path, output_length=None, frame_rate_ratio=1):\n",
    "    cam = cv2.VideoCapture(video_path)\n",
    "    assert cam.isOpened(), \"Open Video %s Failed!\" % video_path\n",
    "    video_length = int(cam.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if output_length is None:\n",
    "        output_length = video_length\n",
    "    i = 0  # default is 0\n",
    "    while (cam.isOpened()) and i < output_length:\n",
    "        ret_val, image = cam.read()\n",
    "        if not ret_val:\n",
    "            break\n",
    "        if i % frame_rate_ratio == 0:\n",
    "            yield image\n",
    "        i += 1\n",
    "    cam.release()\n",
    "\n",
    "\n",
    "def get_video_size(video_path, output_length=None):\n",
    "    cam = cv2.VideoCapture(video_path)\n",
    "    assert cam.isOpened(), \"Open Video %s Failed!\" % video_path\n",
    "    l = int(cam.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if output_length is not None:\n",
    "        l = min(l, output_length)\n",
    "    h = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    w = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    cam.release()\n",
    "    return l, h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_frames(image_list, output_length=None, frame_rate_ratio=1):\n",
    "    image_count = len(image_list)\n",
    "    assert image_count > 0\n",
    "    if output_length is None:\n",
    "        output_length = image_count\n",
    "    for i, path in enumerate(image_list):\n",
    "        if i >= output_length:\n",
    "            break\n",
    "        if i % frame_rate_ratio == 0:\n",
    "            image = cv2.imread(path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            yield image\n",
    "\n",
    "\n",
    "def get_image_size(image_list, output_length=None):\n",
    "    image_count = len(image_list)\n",
    "    assert image_count > 0\n",
    "    image = cv2.imread(image_list[0])\n",
    "    l = len(image_list)\n",
    "    if output_length is not None:\n",
    "        l = min(l, output_length)\n",
    "    h, w = image.shape[:2]\n",
    "    return l, h, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulding VGG19\n",
      "Model Ready!\n"
     ]
    }
   ],
   "source": [
    "model = get_model('vgg19')\n",
    "model.load_state_dict(t.load(weight_file))\n",
    "model = t.nn.DataParallel(model)\n",
    "model.cuda()\n",
    "model.float()\n",
    "model.eval()\n",
    "print(\"Model Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init I/O Paths \n",
    "Select from `organize_image_io_paths` or `organize_video_io_paths`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items count:  502\n"
     ]
    }
   ],
   "source": [
    "_input_ext_ = IMAGE_EXT if input_ext == \"image\" \\\n",
    "    else VIDEO_EXT if input_ext == \"video\" \\\n",
    "    else input_ext if isinstance(input_ext, list) \\\n",
    "    else [input_ext]\n",
    "print(input_type== \"1to1\")\n",
    "print(_input_ext_)\n",
    "if input_type == \"1to1\":\n",
    "    io_paths = organize_1to1_io_paths(input_data, _input_ext_, output_dir, output_ext)\n",
    "else:\n",
    "    io_paths = organize_Nto1_io_paths(input_data, _input_ext_, output_dir, output_ext)\n",
    "total_item = len(io_paths[\"input\"])\n",
    "print(\"Items count: \", total_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prosessed 0 items, ignore 502 existing items. Saved into /home/liuqixuan/datasets/actions/val\n",
      "All work are Finished！\n"
     ]
    }
   ],
   "source": [
    "caption = widgets.Label(\"Ready to work!\")\n",
    "msg = widgets.Label('0/0, process time: 0.0s, total time: 0.0s')\n",
    "bar = widgets.FloatProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    description='[0/0]',\n",
    "    bar_style='',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "    orientation='horizontal'\n",
    ")\n",
    "if show_visualize_process:\n",
    "    imgbox = widgets.Image(format='jpg')\n",
    "    proc_info = widgets.VBox([caption, widgets.HBox([msg, bar]), imgbox])\n",
    "else:\n",
    "    proc_info = widgets.VBox([caption, widgets.HBox([msg, bar])])\n",
    "display(proc_info)\n",
    "ignore_item = 0\n",
    "for i, (input_data, output_path) in enumerate(zip(io_paths[\"input\"], io_paths[\"output\"])):\n",
    "    if os.path.isfile(output_path):\n",
    "        if rebuild_exist_file:\n",
    "            title = '[{}/{}]Rebuild {} from {}'\n",
    "        else:\n",
    "            print('[{}/{}]{} already exist, pass'.format(i, total_item, output_path))\n",
    "            ignore_item += 1\n",
    "            continue\n",
    "    else:\n",
    "        title = '[{}/{}]Build {} from {}'\n",
    "    if isinstance(input_data, str):  # process video\n",
    "        source_position = input_data\n",
    "        loader = load_video_frames(input_data, output_length, frame_rate_ratio)\n",
    "        length, h, w = get_video_size(input_data, output_length)\n",
    "    elif isinstance(input_data, list):  # process images\n",
    "        source_position = os.path.dirname(input_data[0])\n",
    "        loader = load_image_frames(input_data, output_length, frame_rate_ratio)\n",
    "        length, h, w = get_image_size(input_data, output_length)\n",
    "    else:\n",
    "        raise TypeError(\"Expected string or list(string), but got %s\" % type(input_data))\n",
    "    caption.value = title.format(i, total_item, output_path, source_position)\n",
    "    # Video writer\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        output_fps = 15\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        height = int(resize_fac * h)\n",
    "        width = int(resize_fac * w)\n",
    "        caption.value += \"\\nsource:{}x{}  target:{}x{}\".format(h, w, height, width)\n",
    "        if imgbox:\n",
    "            imgbox.width = width\n",
    "            imgbox.height = height\n",
    "        out = cv2.VideoWriter(output_path, fourcc, output_fps, (width, height))\n",
    "        out_h5 = h5py.File(output_path + \".h5\", mode=\"w\")\n",
    "        out_h5[\"height\"] = height\n",
    "        out_h5[\"width\"] = width\n",
    "        t0 = time.time()\n",
    "        for i, image in enumerate(loader):\n",
    "            t1 = time.time()\n",
    "            # generate image with body parts\n",
    "            resized_image = cv2.resize(image, (0, 0), fx=1 * resize_fac, fy=1 * resize_fac,\n",
    "                                       interpolation=cv2.INTER_CUBIC)\n",
    "            to_plot, canvas, joint_list, person_to_joint_assoc = process(model, resized_image, process_speed)\n",
    "            # save outputs\n",
    "            out.write(canvas)\n",
    "            frame_h5 = out_h5.create_group(\"frame%d\" % i)\n",
    "            frame_h5.create_dataset(\"joint_list\", data=joint_list)\n",
    "            frame_h5.create_dataset(\"person_to_joint_assoc\", data=person_to_joint_assoc)\n",
    "            t2 = time.time()\n",
    "            # print messages\n",
    "            msg.value = '{}  process time:{:.3f}s  total time:{:.3f}s'.format(\n",
    "                time.strftime('%H:%M:%S'), (t2 - t1), (t2 - t0))\n",
    "            bar.description = '[{}/{}]'.format(i, length)\n",
    "            bar.value = i / length\n",
    "            if show_visualize_process:\n",
    "                canvas = cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)\n",
    "                imgbox.value = np.array(cv2.imencode('.jpg', canvas)[1]).tostring()\n",
    "    finally:\n",
    "        out.release()\n",
    "        out_h5.close()\n",
    "clear_output()\n",
    "print(\"Prosessed {} items, ignore {} existing items. Saved into {}\".format(\n",
    "    total_item - ignore_item, ignore_item, output_dir))\n",
    "print(\"All work are Finished！\")\n",
    "exit()  # clean GPU memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
